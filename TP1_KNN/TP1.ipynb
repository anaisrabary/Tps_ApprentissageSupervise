{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DESCR': 'mldata.org dataset: mnist-original', 'COL_NAMES': ['label', 'data'], 'target': array([0., 0., 0., ..., 9., 9., 9.]), 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}\n",
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "#QUESTION 1\n",
    "\n",
    "#imprime la structure et un appercu des data\n",
    "print(mnist)\n",
    "#imprime un aperçu des data\n",
    "#print(mnist.data)\n",
    "\n",
    "# imrime la cible ????\n",
    "#print(mnist.target)\n",
    "\n",
    "#longueur de data\n",
    "#len(mnist.data) #70000\n",
    "print(mnist.data.shape) #(70000, 784)\n",
    "print(mnist.target.shape) #(70000,)\n",
    "\n",
    "#mnist.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe :  0.0\n"
     ]
    }
   ],
   "source": [
    "#QUESTION 2\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "mnist=datasets.fetch_mldata('MNIST original')\n",
    "images = mnist.data.reshape((-1,28,28))\n",
    "\n",
    "plt.imshow(images[0],cmap=plt.cm.gray_r,interpolation=\"nearest\")\n",
    "plt.show()\n",
    "\n",
    "print(\"classe : \", mnist.target[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#**************************************\n",
    "#          EXERCICE 2\n",
    "#**************************************\n",
    "#import necessaires\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import neighbors\n",
    "\n",
    "#ECHANTILLONS DE 5000\n",
    "indices = np.random.randint(70000, size=5000)\n",
    "data = mnist.data[indices]\n",
    "target = mnist.target[indices]\n",
    "#pour séparer le dataset en 2 échantillons de trainint et de test\n",
    "xtrain, xtest, ytrain, ytest =train_test_split(data, target, train_size=0.8)\n",
    "\n",
    "clf=neighbors.KNeighborsClassifier(10)\n",
    "clf.fit(xtrain,ytrain)\n",
    "predict = clf.predict(xtest)\n",
    "proba=clf.predict_proba(xtest)\n",
    "score = clf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3eme image : prédiction  5.0 reel :  5.0\n",
      "Pour K=10 score test :  92.60000000000001 %\n"
     ]
    }
   ],
   "source": [
    "#Résultat 1er test\n",
    "print(\"3eme image : prédiction \",predict[3], \"reel : \", ytest[3])\n",
    "print(\"Pour K=10 score test : \", score*100, \"%\")\n",
    "\n",
    "# WHAT ABOUT Predic-proba\n",
    "\n",
    "#3eme image : prédiction  1.0 reel :  1.0\n",
    "#score test :  92.10000000000001 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=15, random_state=None, shuffle=True)\n",
      "Pour K =  2 score =  91.31736526946108 %\n",
      "Pour K =  3 score =  91.31736526946108 %\n",
      "Pour K =  4 score =  91.01796407185628 %\n",
      "Pour K =  5 score =  91.01796407185628 %\n",
      "Pour K =  6 score =  92.51497005988024 %\n",
      "Pour K =  7 score =  92.49249249249249 %\n",
      "Pour K =  8 score =  91.29129129129129 %\n",
      "Pour K =  9 score =  93.993993993994 %\n",
      "Pour K =  10 score =  92.1921921921922 %\n",
      "Pour K =  11 score =  94.29429429429429 %\n",
      "Pour K =  12 score =  91.5915915915916 %\n",
      "Pour K =  13 score =  91.5915915915916 %\n",
      "Pour K =  14 score =  91.5915915915916 %\n",
      "Pour K =  15 score =  90.990990990991 %\n",
      "Pour K =  16 score =  90.69069069069069 %\n"
     ]
    }
   ],
   "source": [
    "#VARIATION des data prises\n",
    "from sklearn.model_selection import KFold\n",
    "k_fold = KFold( n_splits=15, shuffle=True)\n",
    "print(k_fold)\n",
    "k=1\n",
    "for train_indices,test_indices in k_fold.split(data,target):\n",
    "    k+=1\n",
    "    clf.fit(data[train_indices],target[train_indices])\n",
    "    clf.predict(data[test_indices])\n",
    "    print(\"Pour K = \", k, \"score = \", clf.score(data[test_indices],target[test_indices])*100, \"%\")\n",
    "#Pour K =  2 score =  91.31736526946108 %\n",
    "#Pour K =  3 score =  91.31736526946108 %\n",
    "#Pour K =  4 score =  91.01796407185628 %\n",
    "#Pour K =  5 score =  91.01796407185628 %\n",
    "#Pour K =  6 score =  92.51497005988024 %\n",
    "#Pour K =  7 score =  92.49249249249249 %\n",
    "#Pour K =  8 score =  91.29129129129129 %\n",
    "#Pour K =  9 score =  93.993993993994 %\n",
    "#Pour K =  10 score =  92.1921921921922 %\n",
    "#Pour K =  11 score =  94.29429429429429 %\n",
    "#Pour K =  12 score =  91.5915915915916 %\n",
    "#Pour K =  13 score =  91.5915915915916 %\n",
    "#Pour K =  14 score =  91.5915915915916 %\n",
    "#Pour K =  15 score =  90.990990990991 %\n",
    "#Pour K =  16 score =  90.69069069069069 %\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIATION DE K sur les même xtrain, ytrain\n",
    "#AUTRE METHODE + Simple\n",
    "for k in range(2,16):\n",
    "    clf=neighbors.KNeighborsClassifier(k)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    clf.predict(xtest)\n",
    "    print(\"Pour K = \", k, \"score = \", clf.score(xtest,ytest)*100, \"%\")\n",
    "#Pour K =  2 score =  91.3 %\n",
    "#Pour K =  3 score =  92.80000000000001 %\n",
    "#Pour K =  4 score =  92.7 %\n",
    "#Pour K =  5 score =  93.30000000000001 %\n",
    "#Pour K =  6 score =  92.60000000000001 %\n",
    "#Pour K =  7 score =  92.4 %\n",
    "#Pour K =  8 score =  92.10000000000001 %\n",
    "#Pour K =  9 score =  91.9 %\n",
    "#Pour K =  10 score =  92.10000000000001 %\n",
    "#Pour K =  11 score =  92.0 %\n",
    "#Pour K =  12 score =  92.2 %\n",
    "#Pour K =  13 score =  91.60000000000001 %\n",
    "#Pour K =  14 score =  91.2 %\n",
    "#Pour K =  15 score =  91.3 %\n",
    "\n",
    "# TODO : check si K = 3 est pas mieux ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour un train/test =  10 %, score =  81.44444444444444 %\n",
      "Pour un train/test =  20 %, score =  86.575 %\n",
      "Pour un train/test =  30 %, score =  88.31428571428572 %\n",
      "Pour un train/test =  40 %, score =  90.0 %\n",
      "Pour un train/test =  50 %, score =  91.12 %\n",
      "Pour un train/test =  60 %, score =  91.05 %\n",
      "Pour un train/test =  70 %, score =  89.8 %\n",
      "Pour un train/test =  80 %, score =  91.2 %\n",
      "Pour un train/test =  90 %, score =  93.2 %\n"
     ]
    }
   ],
   "source": [
    "# VARIATION des échantillons\n",
    "for k in range(1,10):\n",
    "    x_train, x_test, y_train, y_test =train_test_split(data, target, train_size=k*0.1)\n",
    "    clf.fit(x_train,y_train)\n",
    "    clf.predict(x_test)\n",
    "    print(\"Pour un train/test = \", (k*10), \"%, score = \", clf.score(x_test,y_test)*100, \"%\")\n",
    "    \n",
    "#Pour un train/test =  10 %, score =  81.44444444444444 %\n",
    "#Pour un train/test =  20 %, score =  86.575 %\n",
    "#Pour un train/test =  30 %, score =  88.31428571428572 %\n",
    "#Pour un train/test =  40 %, score =  90.0 %\n",
    "#Pour un train/test =  50 %, score =  91.12 %\n",
    "#Pour un train/test =  60 %, score =  91.05 %\n",
    "#Pour un train/test =  70 %, score =  89.8 %\n",
    "#Pour un train/test =  80 %, score =  91.2 %\n",
    "#Pour un train/test =  90 %, score =  93.2 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour un échantillon de taille =  5000 ,score =  92.5 %\n",
      "Pour un échantillon de taille =  10000 ,score =  93.60000000000001 %\n",
      "Pour un échantillon de taille =  15000 ,score =  94.63333333333334 %\n",
      "Pour un échantillon de taille =  20000 ,score =  94.69999999999999 %\n",
      "Pour un échantillon de taille =  25000 ,score =  95.54 %\n"
     ]
    }
   ],
   "source": [
    "#VARIATION de la taille des échantillons\n",
    "for k in range(1,6):\n",
    "    indices = np.random.randint(70000, size=5000*k)\n",
    "    data = mnist.data[indices]\n",
    "    target = mnist.target[indices]\n",
    "    #pour séparer le dataset en 2 échantillons de trainint et de test\n",
    "    x_train, x_test, y_train, y_test =train_test_split(data, target, train_size=0.8)\n",
    "    clf=neighbors.KNeighborsClassifier(10)\n",
    "    clf.fit(x_train,y_train)\n",
    "    clf.predict(x_test)\n",
    "    print(\"Pour un échantillon de taille = \", (k*5000), \",score = \", clf.score(x_test,y_test)*100, \"%\")\n",
    "\n",
    "#Pour un échantillon de taille =  5000 ,score =  92.5 %\n",
    "#Pour un échantillon de taille =  10000 ,score =  93.60000000000001 %\n",
    "#Pour un échantillon de taille =  15000 ,score =  94.63333333333334 %\n",
    "#Pour un échantillon de taille =  20000 ,score =  94.69999999999999 %\n",
    "#Pour un échantillon de taille =  25000 ,score =  95.54 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec la distance Eucliedienne, le score =  95.7 %\n",
      "Avec la distance de Manhattan, le score =  91.3 %\n",
      "Avec la distance de Chebyshev, le score =  63.7 %\n",
      "Avec la distance de Hamming, le score =  61.9 %\n",
      "Avec la distance de Minkowski p=3 , le score =  92.5 %\n",
      "Avec la distance de Minkowski p=4, le score =  92.5 %\n",
      "Avec la distance de Minkowski p=4, le score =  92.5 %\n"
     ]
    }
   ],
   "source": [
    "# VARIATION de la distance\n",
    "# Par défaut, la distance est la distance euclidienne (minkowskiDistance avec p = 2)\n",
    "# see here for more details : https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html \n",
    "\n",
    "print(\"Avec la distance Eucliedienne, le score = \", clf.score(xtest,ytest)*100, \"%\")\n",
    "\n",
    "# test ManhattanDistance \"manhattan\"\n",
    "manha=neighbors.KNeighborsClassifier(10, metric='manhattan')\n",
    "manha.fit(xtrain,ytrain)\n",
    "manha.predict(xtest)\n",
    "print(\"Avec la distance de Manhattan, le score = \", manha.score(xtest,ytest)*100, \"%\")\n",
    "\n",
    "#test ChebyshevDistance \"chebyshev\"\n",
    "cheby=neighbors.KNeighborsClassifier(10, metric='chebyshev')\n",
    "cheby.fit(xtrain,ytrain)\n",
    "cheby.predict(xtest)\n",
    "print(\"Avec la distance de Chebyshev, le score = \", cheby.score(xtest,ytest)*100, \"%\")\n",
    "\n",
    "#test Hamming distance\n",
    "ham=neighbors.KNeighborsClassifier(10, metric='hamming')\n",
    "ham.fit(xtrain,ytrain)\n",
    "ham.predict(xtest)\n",
    "print(\"Avec la distance de Hamming, le score = \", ham.score(xtest,ytest)*100, \"%\")\n",
    "\n",
    "#test minkowski p=3,4,5\n",
    "mink3=neighbors.KNeighborsClassifier(10, p=3, metric='minkowski')\n",
    "mink3.fit(xtrain,ytrain)\n",
    "mink3.predict(xtest)\n",
    "print(\"Avec la distance de Minkowski p=3 , le score = \", mink3.score(xtest,ytest)*100, \"%\")\n",
    "\n",
    "mink4=neighbors.KNeighborsClassifier(10, p=3, metric='minkowski')\n",
    "mink4.fit(xtrain,ytrain)\n",
    "mink4.predict(xtest)\n",
    "print(\"Avec la distance de Minkowski p=4, le score = \", mink4.score(xtest,ytest)*100, \"%\")\n",
    "\n",
    "mink5=neighbors.KNeighborsClassifier(10, p=3, metric='minkowski')\n",
    "mink5.fit(xtrain,ytrain)\n",
    "mink5.predict(xtest)\n",
    "print(\"Avec la distance de Minkowski p=5, le score = \", mink5.score(xtest,ytest)*100, \"%\")\n",
    "\n",
    "#Avec la distance Eucliedienne, le score =  95.7 %\n",
    "#Avec la distance de Manhattan, le score =  91.3 %\n",
    "#Avec la distance de Chebyshev, le score =  63.7 %\n",
    "#Avec la distance de Hamming, le score =  61.9 %\n",
    "#Avec la distance de Minkowski p=3 , le score =  92.5 %\n",
    "#Avec la distance de Minkowski p=4, le score =  92.5 %\n",
    "#Avec la distance de Minkowski p=5, le score =  92.5 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MESURE avec njobs\n",
    "# TODO :A FAIRE TOURNER !!!!!\n",
    "import time\n",
    "job1=neighbors.KNeighborsClassifier(10, n_jobs=1)\n",
    "job=neighbors.KNeighborsClassifier(10, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps entrainement 1 job :  0.1735365390777588 sec.\n",
      "temps prediction 1 job :  5.645895719528198 sec.\n",
      "temps entrainement -1 job :  0.15656518936157227 sec.\n",
      "temps prediction -1 job :  1.7062718868255615 sec.\n"
     ]
    }
   ],
   "source": [
    "# MESURE avec njobs\n",
    "# TODO :A FAIRE TOURNER !!!!!\n",
    "#import timeit\n",
    "#job1=neighbors.KNeighborsClassifier(10, n_jobs=1)\n",
    "#job=neighbors.KNeighborsClassifier(10, n_jobs=-1)\n",
    "# for help https://docs.python.org/2/library/timeit.html \n",
    "\n",
    "def trainjob1():\n",
    "    starttime= time.time()\n",
    "    job1.fit(xtrain,ytrain)\n",
    "    endtime = time.time()\n",
    "    print(\"temps entrainement 1 job : \",  endtime - starttime , \"sec.\")\n",
    "    \n",
    "def predjob1():\n",
    "    starttime= time.time()\n",
    "    job1.predict(xtest)\n",
    "    endtime = time.time()\n",
    "    job1.score(xtest,ytest)\n",
    "    print(\"temps prediction 1 job : \",  endtime - starttime , \"sec.\")\n",
    "\n",
    "def trainjob():\n",
    "    starttime= time.time()\n",
    "    job.fit(xtrain,ytrain)\n",
    "    endtime = time.time()\n",
    "    print(\"temps entrainement -1 job : \",  endtime - starttime , \"sec.\")\n",
    "    \n",
    "\n",
    "def predjob():\n",
    "    starttime= time.time()\n",
    "    job.predict(xtest)\n",
    "    endtime = time.time()\n",
    "    job.score(xtest,ytest)\n",
    "    print(\"temps prediction -1 job : \",  endtime - starttime , \"sec.\")\n",
    "\n",
    "trainjob1()\n",
    "predjob1()\n",
    "trainjob()\n",
    "predjob()\n",
    "\n",
    "\n",
    "#temps entrainement 1 job :  0.1735365390777588 sec.\n",
    "#temps prediction 1 job :  5.645895719528198 sec.\n",
    "#temps entrainement -1 job :  0.15656518936157227 sec.\n",
    "#temps prediction -1 job :  1.7062718868255615 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quels sont les avantages de KNN ??\n",
    "# -optimalité ?\n",
    "# - temps de calcul ?\n",
    "# - passage à l'échelle ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
